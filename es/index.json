[{"categories":null,"content":"Bio Father. Husbsand. Pastafari. The one who loves developing software. Manufactured in 1971 in Barcelona (Spain) Programming things for the last 30+ years. In love with C#, Java, SQL, software architecture, async patterns \u0026 more. Ex-teacher, Blogger, Speaker, Geek \u0026 family guy, living in Andorra since 2001. Microsoft MVP 2002-2016, MAP, MCC Active member and moderator in the good old MS newsgroups and forums for almost two decades. Founder of AndorraDotNet, the first dotNet user group in the country. Host of several events, like Geek-a-palooza. Now in a well deserved retirement ","date":"2020-05-01","objectID":"/es/about/:1:0","tags":null,"title":"About me","uri":"/es/about/"},{"categories":null,"content":"I like Coding. Family. Mountains. Sports. Food. Nature. Feminism. Human rights. Scifi. Fantasy. Traveling. Science. Atheism. ","date":"2020-05-01","objectID":"/es/about/:2:0","tags":null,"title":"About me","uri":"/es/about/"},{"categories":null,"content":"I dislike Anti-vaxxers. Racism. Religious fundamentalists. Pseudoscience. Lack of imagination or proud on ignorance. Politicians. ","date":"2020-05-01","objectID":"/es/about/:3:0","tags":null,"title":"About me","uri":"/es/about/"},{"categories":null,"content":"Tech profile Languages and technologies I‚Äôve learnt through the years. Language/Technology Start End Expertise Basic 1983 1988 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Assembler 1986 1986 ‚≠ê C 1990 1997 ‚≠ê‚≠ê‚≠ê‚≠ê C++ 1992 2000 ‚≠ê‚≠ê‚≠ê Pascal 1992 1994 ‚≠ê‚≠ê‚≠ê ObjectPal 1994 1994 ‚≠ê Visual Basic 1994 2002 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê SQL (TSQL/PS-SQL) 1994 - ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Clipper 1998 1999 ‚≠ê‚≠ê‚≠ê Delphi 1998 2002 ‚≠ê‚≠ê‚≠ê‚≠ê Java 1998 2004 ‚≠ê‚≠ê‚≠ê‚≠ê ActionScript 1999 1999 ‚≠ê Visual Basic.NET 2002 2010 ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê C# 2002 - ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Javascript 2008 - ‚≠ê‚≠ê‚≠ê F# 2012 2012 ‚≠ê‚≠ê Typescript 2018 2018 ‚≠ê‚≠ê CSS 2018 - ‚≠ê‚≠ê Python 2019 - ‚≠ê‚≠ê Go 2020 - ‚≠ê ","date":"2020-05-01","objectID":"/es/about/:4:0","tags":null,"title":"About me","uri":"/es/about/"},{"categories":null,"content":"Who am I? Speaking at dotnet conference View this post on Instagram A post shared by Lluis Franco (@francolluis) on Jan 1, 2019 at 1:12pm PST View this post on Instagram A post shared by Lluis Franco (@francolluis) on Jul 14, 2018 at 11:19am PDT View this post on Instagram A post shared by Lluis Franco (@francolluis) on Aug 19, 2018 at 1:30pm PDT View this post on Instagram A post shared by Lluis Franco (@francolluis) on Feb 12, 2018 at 6:36am PST View this post on Instagram A post shared by Lluis Franco (@francolluis) on Aug 9, 2019 at 12:43am PDT View this post on Instagram A post shared by Lluis Franco (@francolluis) on Aug 9, 2019 at 12:38am PDT View this post on Instagram A post shared by Lluis Franco (@francolluis) on Mar 2, 2019 at 5:43am PST ","date":"2020-05-01","objectID":"/es/about/:5:0","tags":null,"title":"About me","uri":"/es/about/"},{"categories":["Development","Fundamentals"],"content":"Ir al √≠ndice de la serie ","date":"2012-02-10","objectID":"/es/functional-programming-for-the-rest-of-us/:0:0","tags":["Functional","Programming","Lambda","History"],"title":"Programaci√≥n funcional para el resto de nosotros","uri":"/es/functional-programming-for-the-rest-of-us/"},{"categories":["Development","Fundamentals"],"content":"Mi idea inicial Originalmente, en mi serie sobre la Task Parallel Library estaba pensando en incluir alg√∫n post sobre programaci√≥n funcional, pero cuando encontr√© esta peque√±a joya decid√≠ pedir permiso a Luis para poder incluir una copia en mi blog, ya que ni en sue√±os podr√≠a yo haber escrito algo tan completo. Mis felicitaciones! Nota Art√≠culo reproducido con permiso del traductor original. Dale un vistazo al excelente trabajo y consulta la versi√≥n traducida de Luis Mendoza, basado en el post original de Slava Akhmechet. Sin m√°s os dejo con uno de los mejores art√≠culos que he podido leer √∫ltimamente. A disfrutar! ","date":"2012-02-10","objectID":"/es/functional-programming-for-the-rest-of-us/:1:0","tags":["Functional","Programming","Lambda","History"],"title":"Programaci√≥n funcional para el resto de nosotros","uri":"/es/functional-programming-for-the-rest-of-us/"},{"categories":["Development","Fundamentals"],"content":"Art√≠culo original ","date":"2012-02-10","objectID":"/es/functional-programming-for-the-rest-of-us/:2:0","tags":["Functional","Programming","Lambda","History"],"title":"Programaci√≥n funcional para el resto de nosotros","uri":"/es/functional-programming-for-the-rest-of-us/"},{"categories":["Development","Fundamentals"],"content":"Introducci√≥n Los programadores son procrastinadores (o sea, personas que aplazan las cosas). Llegan, toman un poco de caf√©, revisan su bandeja de entrada, leen sus actualizaciones de RSS, leen las noticias, dan un vistazo a los art√≠culos m√°s recientes en los sitios de tecnolog√≠a, examinan las discusiones pol√≠ticas en los secciones designadas de los foros de programaci√≥n‚Ä¶ se restriegan los ojos y echan otro vistazo para asegurarse de no perderse nada. Van a comer. Regresan, inician el IDE por unos minutos. Revisan la bandeja de entrada. Toman un poco de caf√©. Antes de darse cuenta, el d√≠a de trabajo ya termin√≥. Pero, de vez en cuando, te encuentras con art√≠culos verdaderamente desafiantes. Si buscas en el lugar correcto encontrar√°s al menos uno cada pocos d√≠as. Como son dif√≠ciles de entender y necesitas tiempo para leerlos, empiezan a acumularse. Antes de darte cuenta, tienes una larga lista de v√≠nculos y una carpeta llena de archivos PDF y quisieras tener un a√±o en una peque√±a caba√±a a la mitad del bosque sin nadie a kil√≥metros a la redonda para que finalmente puedas comprenderlos. Estar√≠a bien que alguien viniera cada ma√±ana mientras das un paseo por el r√≠o para dejarte algo de comida y llevarse la basura. No s√© de tu lista, pero una buena parte de la m√≠a tiene que ver con programaci√≥n funcional. Estos son generalmente los art√≠culos m√°s dif√≠ciles de entender. Escritos en un √°spero lenguaje acad√©mico, aun los ‚Äúveteranos de la industria de Wall Street con diez a√±os de experiencia‚Äù no entienden de qu√© tratan los art√≠culos sobre programaci√≥n funcional (tambi√©n llamada FP, por sus siglas en ingl√©s). Si preguntas al administrador de proyectos de Citi Group o de Deutsche Bank por qu√© usan JMS en lugar de Erlang te dir√°n que no pueden usar lenguajes acad√©micos para aplicaciones de fortaleza industrial (Cuando buscaba trabajo en el oto√±o de 2005 a menudo hice esa pregunta. Es bastante divertido recordar cuantos rostros con signos de interrogaci√≥n vi. Uno podr√≠a pensar que a $300,000 la pieza de estas personas, al menos tendr√≠an un buen entendimiento de las herramientas que tienen disponibles). El problema es que algunos de los sistemas m√°s complejos con los requerimientos m√°s r√≠gidos est√°n escritos usando elementos de programaci√≥n funcional. Algo no cuadra. Es cierto que los art√≠culos sobre FP (recuerda que son las siglas en ingl√©s para programaci√≥n funcional) son dif√≠ciles de entender, pero no tendr√≠an por qu√© serlo. Las razones para que haya ese obst√°culo al conocimiento son meramente hist√≥ricas. No hay nada inherentemente dif√≠cil en los conceptos de FP. Considera este art√≠culo como ‚Äúuna gu√≠a accesible para entener FP‚Äù, un puente entre nuestras mentes imperativas hacia el mundo de FP. Prep√°rate un caf√© y sigue leyendo. Con un poco de suerte, en poco tus amigos estar√°n bromeando sobre tus nuevas ideas sobre FP. As√≠ que, ¬øqu√© es la programaci√≥n funcional o FP? ¬øC√≥mo se produce? ¬øEs comestible? Si es tan √∫til como proclaman sus defensores, ¬øpor qu√© no es m√°s usada en la industria? ¬øPor qu√© parece que solo personas con grado de doctorado lo quieren usar? M√°s importante, ¬øpor qu√© es tan dif√≠cil de aprender? ¬øQu√© es todo eso de cierres (closures), continuaciones, currying, evaluaci√≥n tard√≠a y cero efectos colaterales? ¬øC√≥mo puede usarse en proyectos que no tengan que ver con universidades? ¬øPor qu√© parece tan distinto de todo lo bueno, santo y querido por nuestros corazones imperativos? Aclararemos todo esto pronto. Empecemos explicando las razones por las que existe esa gran barrera entre el mundo real y los art√≠culos acad√©micos. La respuesta es tan sencilla como dar un paseo por el parque. ","date":"2012-02-10","objectID":"/es/functional-programming-for-the-rest-of-us/:2:1","tags":["Functional","Programming","Lambda","History"],"title":"Programaci√≥n funcional para el resto de nosotros","uri":"/es/functional-programming-for-the-rest-of-us/"},{"categories":["Development","Fundamentals"],"content":"Un paseo por el parque ¬°Enciende la m√°quina del tiempo! Nuestro paseo empieza unos dos mil a√±os atr√°s, en una bello y soleado d√≠a de la primavera de 380 a.C. A las afueras de las murallas de Atenas, bajo la pl√°cida sombra de los olivos, Plat√≥n caminaba rumbo a la Academia con un joven pupilo. El clima estaba agradable, la cena hab√≠a estado deliciosa, y la conversaci√≥n empez√≥ a tomar tintes filos√≥ficos. ‚ÄúMira a esos dos estudiantes‚Äù, dijo Plat√≥n escogiendo cuidadosamente las palabras para hacer una pregunta educativa. ‚Äú¬øCual de ellos te parece m√°s alto?‚Äù El joven pupilo mir√≥ hacia la cuenca de agua en la que dos hombres estaban parados. ‚ÄúSon m√°s o menos de la misma altura‚Äù, contest√≥. Plat√≥n pregunt√≥: ‚Äú¬øQu√© quieres decir con ‚Äòm√°s o menos‚Äô?‚Äù. El joven contesto: ‚ÄúBueno, desde aqu√≠ se ven de la misma estatura, pero si estuviera m√°s cerca seguramente ver√≠a alguna diferencia‚Äù. Plat√≥n sonri√≥. Hab√≠a llevado al joven en la direcci√≥n correcta. ‚Äú¬øAs√≠ que dir√≠as que no hay ninguna cosa perfectamente igual a otra en nuestro mundo?‚Äù Despu√©s de pensar un poco, el joven respondi√≥: ‚ÄúNo lo creo. Toda cosa es al menos un poco diferente de otra, aunque no podamos ver la diferencia‚Äù. ¬°Hab√≠a dado en el clavo! Plat√≥n dijo: ‚ÄúEntonces, si ninguna cosa es perfectamente igual a otra en este mundo, ¬øc√≥mo crees que entendemos el concepto de equidad ‚Äòperfecta‚Äô?‚Äù El joven se qued√≥ perplejo. ‚ÄúNo lo s√©‚Äù, contest√≥. As√≠ nacio el primer esfuerzo por entender la naturaleza de las matem√°ticas. Plat√≥n sugiri√≥ que todo en nuestro mundo es solo una aproximaci√≥n de la perfecci√≥n. Adem√°s, se dio cuenta de que entendemos el concepto de perfecci√≥n aunque no la hayamos visto. Lleg√≥ a la conclusi√≥n de que las formas matem√°ticas perfectas viven en otro mundo y que de alguna forma sabemos de ellas al tener una conexi√≥n con ese universo ‚Äúalternativo‚Äù. Sabemos bien que no hay un c√≠rculo perfecto que podamos observar. Pero entendemos qu√© es un c√≠rculo perfecto y podemos describirlo mediante ecuaciones. ¬øQu√© son, entonces, las matem√°ticas? ¬øPor qu√© esta descrito nuestro universo con leyes matem√°ticas? ¬øSer√° posible que todos los fen√≥menos del universo sean descritos mediante las matem√°ticas? (Esta parece ser una cuesti√≥n muy controversial. Los f√≠sicos y los matem√°ticos se ven obligados a reconocer que no esta del todo claro si todo en el universo obedece leyes matem√°ticas o no.) La filosof√≠a de las matem√°ticas es una materia de estudio muy compleja. Como muchas disciplinas filos√≥ficas genera m√°s preguntas que respuestas. Buena parte de los concensos alcanzados giran en torno a que las matem√°ticas son realmente un rompecabezas: podemos declaramos un conjunto b√°sico de principios que no entran en conflicto, y un conjunto de reglas sobre c√≥mo operan estos principios. Entonces podemos usar estas reglas como base para reglas m√°s y m√°s complejas. Los matem√°ticos le llaman a esto un ‚Äúsistema formal‚Äù o ‚Äúc√°lculo‚Äù. Podr√≠amos construir un sistema formal del Tetris si quisieramos. De hecho, una implementaci√≥n del Tetris que funcione es un sistema formal, solo que especificado usando una representaci√≥n inusual. Una civilizaci√≥n de criaturas peludas que existiera en Alfa Centauri no podr√≠a leer nuestros formalismos del Tetris y de los c√≠rculos porque su √∫nico √≥rgano sensorial solo percibiera olores. Lo m√°s probable es que nunca sabr√≠an nada del Tetris, pero s√≠ tendr√≠an un formalismo para los c√≠rculos. Probablemente nosotros no podr√≠amos entenderlo, pues nuestro sentido del olfato no ser√≠a tan sofisticado, pero una vez que dejamos de lado la representaci√≥n del formalismo (a trav√©s de diversos instrumentos sensoriales y t√©cnicas de lectura para entender el lenguaje), los conceptos fundamentales son entendibles para cualquier civilizaci√≥n inteligente. Es interesante notar que aunque no existiera una civilizaci√≥n inteligente en el universo, los formalismos del Tetris y de los c√≠rculos estar√≠an ah√≠ para ser examinados, solo que nadie los estar√≠a buscando. Si una civilizaci√≥n inteligente apareciese,","date":"2012-02-10","objectID":"/es/functional-programming-for-the-rest-of-us/:2:2","tags":["Functional","Programming","Lambda","History"],"title":"Programaci√≥n funcional para el resto de nosotros","uri":"/es/functional-programming-for-the-rest-of-us/"},{"categories":["Development","Fundamentals"],"content":"Un poco de historia (Siempre he odiado las lecciones de historia que presentan cronol√≥gicamente fechas, nombres y eventos de forma mec√°nica. Para m√≠, la historia es sobre las vidas de las personas que cambiaron el mundo. Es sobre sus razones personales que les llevaron a actuar de cierta forma, y los mecanismos por medio de los cuales cambiaron millones de vidas. Por esta raz√≥n, esta secci√≥n hist√≥rica es irremediablemente incompleta. Solo las personas y los eventos importantes son discutidos.) Cambiemos de velocidad en la m√°quina del tiempo. Esta vez viajaremos a un punto m√°s cercano, a la decada de 1930. La Gran Depresi√≥n estaba asolando a todo el mundo. Casi toda familia de toda clase social se vi√≥ afectada por la tremenda recesi√≥n econ√≥mica. Muy pocos santuarios quedaron donde la gente estaba a salvo de la pobreza. Pocas personas tuvieron la fortuna de estar en alguno de esos santuarios, pero exist√≠an. Nuestro inter√©s se centrar√° en los matem√°ticos de la Universidad de Princeton. Las nuevas oficinas construidas en estilo g√≥tico daban a Princeton un aire de para√≠so. L√≥gicos (de la rama matem√°tica de la l√≥gica) de todo el mundo fueron invitados a Princeton para construir un nuevo departamento. Mientras muchos en norteam√©rica no pod√≠an ni poner una pieza de pan en sus mesas para la cena, techos altos, paredes cubiertas de madera tallada, discusiones diarias con una taza de t√©, y paseos por el bosque eran algunas de las condiciones de Princeton. Uno de los matem√°ticos viviendo ese lujoso estilo de vida fue un joven llamado Alonzo Church. Alonzo recibi√≥ un grado acad√©mico en Princeton, y fue persuadido a quedarse para un postgrado. Alonzo sent√≠a que la arquitectura del lugar era m√°s un lujo que algo necesario. Rara vez se le ve√≠a discutiendo sobre matem√°ticas con una taza de t√©, y no le gustaban los paseos por el bosque. Alonzo era solitario. Era m√°s productivo cuando trabajaba por su cuenta. No obstante, Alonzo ten√≠a contacto regular con otros habitantes de Princeton, entre ellos Alan Turing, John von Neumann, y Kurt G√∂del. Los cuatro estaban interesados en los sistemas formales. No prestaban mucha atenci√≥n al mundo f√≠sico; les resultaban m√°s interesantes problemas con rompecabezas matem√°ticos abstractos. Sus rompecabezas ten√≠an algo en com√∫n: los cuatro estaban interesados en responder preguntas sobre computaci√≥n. Si tuvieramos m√°quinas con infinito poder computacional, ¬øQue problemas podr√≠amos resolver? ¬øPodr√≠an darse soluciones autom√°ticamente? ¬øQuedar√≠an algunos problemas sin resolver? ¬øPor qu√©? ¬øPodr√≠an maquinas con diferentes dise√±os ser iguales en poder? En cooperaci√≥n con otros, Alonzo desarroll√≥ un sistema formal llamado c√°lculo lambda. El sistema era esencialmente un lenguaje de programaci√≥n para una de esas m√°quinas imaginarias. Se basaba en funciones que tomaban otras funciones como par√°metros, y que devolv√≠an funciones como resultado. La funci√≥n en su papel de materia prima fue identificada con la letra griega lambda(Œª) ah√≠ el nombre del sistema (Cuando estaba aprendiendo programaci√≥n funcional me qued√© muy confundido por el t√©rmino ‚Äúlamda‚Äù porque no sab√≠a qu√© significaba realmente. En este contexto lambda es una funci√≥n. El uso de la letra griega es porque era m√°s f√°cil escribirla en notaci√≥n matem√°tica. Cada vez que escuches el t√©rmino ‚Äúlambda‚Äù cuando se habla de programaci√≥n funcional traducelo en tu mente como ‚Äúfunci√≥n‚Äù). Usando este formalismo, Alonzo pudo razonar sobre muchas de las cuestiones antes planteadas, y lleg√≥ a respuestas concluyentes. Independientemente de Alonzo, Alan Turing realiz√≥ un trabajo similar. Desarroll√≥ un formalismo diferente (ahora conocido como la m√°quina de Turing), y lo us√≥ para llegar a conclusiones similares a las de Alonzo. Despu√©s se demostr√≥ que la m√°quina de Turing y el c√°lculo lamda son equivalentes en poder. Aqu√≠ es donde la historia terminar√≠a. Yo terminar√≠a el art√≠culo, y tu navegar√≠as a otra p√°gina, si no fuera por el comienzo de la Segunda Guerra Mundial. El mundo estaba","date":"2012-02-10","objectID":"/es/functional-programming-for-the-rest-of-us/:2:3","tags":["Functional","Programming","Lambda","History"],"title":"Programaci√≥n funcional para el resto de nosotros","uri":"/es/functional-programming-for-the-rest-of-us/"},{"categories":["Development","Fundamentals"],"content":"Programaci√≥n Funcional La programaci√≥n funcional es la implementaci√≥n pr√°ctica de las ideas de Alonzo Church. No todas las ideas del c√°lculo lambda se implementan en la pr√°ctica porque el c√°lculo lambda no fue dise√±ado para trabajar bajo limitaciones f√≠sicas. Por tanto, como en la programaci√≥n orientada a objetos, la programaci√≥n funcional es un conjunto de ideas, no un conjunto estricto de reglas. Hay muchos lenguajes de programaci√≥n funcional, y la mayor√≠a hacen las cosas de formas muy diferentes entre s√≠. En este art√≠culo explicar√© las ideas m√°s ampliamente usadas en los lenguajes funcionales usando ejemplos tomados del lenguaje Java (s√≠, puedes escribir programas funcionales en Java si eres masoquista). En las siguientes secciones tomaremos Java tal cual, y le haremos modificaciones para transformarlo en lenguaje funcional √∫til. Empecemos nuestro viaje. El c√°lculo lambda fue creado para investigar problemas relacionados con c√°lculo. La programaci√≥n funcional, por tanto, trata principalmente con c√°lculo, y, ¬°sorpresa!, lo hace mediante funciones. La funci√≥n es la unidad b√°sica en programaci√≥n funcional. Las funciones son usadas para pr√°cticamente todo, aun para los c√°lculos m√°s simples. Hasta las variables son reemplazadas con funciones. En programaci√≥n funcional las variables son simplemente accesos directos a expresiones (para no tener que escribir todo en una misma l√≠nea). No pueden ser modificadas. Todas las variables pueden ser asignadas solo una vez. En t√©rminos de Java esto significa que cada variable es declarada como final (o const si hablamos de C++). No hay variables mutables en FP: final int i = 5; final int j = i + 3; Dado que cada variable en FP es final, podemos llegar a dos conclusiones interesantes. Primero, que no tiene sentido escribir la palabra clave final y segundo, que no tiene sentido llamar a las variables, pues‚Ä¶ variables. Haremos estas dos modificaciones a Java: cada variable declarada en nuestro Java funcional sera final por default, y nos referiremos a las variables como s√≠mbolos. Para ahora probablemente te estas preguntando c√≥mo podr√≠as escribir algo razonablemente complicado en nuestro lenguaje reci√©n creado. ¬°Si todo s√≠mbolo es inmutable, entonces no podemos cambiar el estado de nada! Esto no es estrictamente cierto. Cuando Alonzo estaba trabajando en el c√°lculo lambda no estaba interesado en mantener un estado para ser modificado posteriormente. Estaba interesado en realizar operaciones sobre datos (tambien conocidos como ‚Äúmaterial de c√°lculo‚Äù). Como sea, el c√°lculo lambda es equivalente en poder a la m√°quina de Turing. Un lenguaje funcional puede hacer lo mismo que un lenguaje imperativo. ¬øC√≥mo, entonces, podemos obtener los mismos resultados? En realidad los programas funcionales pueden mantener un estado, pero no usan las variables para eso. Usan funciones. El estado es mantenido en los par√°metros de la funci√≥n, en la pila. Si deseas mantener un estado para modificarlo posteriormente, escribes una funci√≥n recursiva. Como ejemplo, escribamos una funci√≥n que devuelva una cadena de car√°cteres de Java al rev√©s. Recuerda que cada variable (m√°s bien, cada s√≠mbolo) es final por default (Es interesante notar que las cadenas de Java son inmutables de todas formas. Es aun m√°s interesante explorar las razones de esta falsedad, pero nos distraer√≠amos de nuestro objetivo). String al_reves(String arg) { if (arg.length() == 0) { return arg; } else { return al_reves( arg.substring(1, arg.length()) + arg.substring(0, 1)); } } Esta funci√≥n es lenta porque se llama a s√≠ misma repetidamente (Muchos de los compiladores de lenguajes funcionales optimizan las funciones recursivas transformandolas en sus contrapartes iterativas siempre que sea posible. A eso se le llama optimizaci√≥n de llamadas a la inversa o Tail recursion). Es una devoradora de memoria porque repetidamente asigna memoria a los objetos. Pero est√° escrita en estilo funcional. Quiz√° te preguntes porque alguien querr√≠a un programa de esta forma. ","date":"2012-02-10","objectID":"/es/functional-programming-for-the-rest-of-us/:2:4","tags":["Functional","Programming","Lambda","History"],"title":"Programaci√≥n funcional para el resto de nosotros","uri":"/es/functional-programming-for-the-rest-of-us/"},{"categories":["Development","Fundamentals"],"content":"Que sigue? Este art√≠culo solo toca la superficie de la programaci√≥n funcional. A veces un peque√±o esbozo puede convertirse en algo grande, y en nuestro caso eso es algo muy bueno. En el futuro planeo escribir sobre teor√≠a de categor√≠as, monads, estructuras de datos funcionales, sistemas de escritura en lenguajes funcionales, concurrencia funcional, bases de datos funcionales y mucho m√°s. Si logro escribir (y en el proceso, aprender) sobre la mitad de estos temas, mi vida estar√° completa. Mientras tanto, Google es nuestro amigo. ","date":"2012-02-10","objectID":"/es/functional-programming-for-the-rest-of-us/:2:5","tags":["Functional","Programming","Lambda","History"],"title":"Programaci√≥n funcional para el resto de nosotros","uri":"/es/functional-programming-for-the-rest-of-us/"},{"categories":["Development","Fundamentals"],"content":"Tienes alg√∫n comentario? Si tienes alguna pregunta, comentario, o sugerencia, por favor d√©jame una nota en coffeemug(AT)gmail.com (este es el correo electr√≥nico de Slava Akhmechet, el autor original). Ser√° un placer conocer tus opiniones. Ir al √≠ndice de la serie ","date":"2012-02-10","objectID":"/es/functional-programming-for-the-rest-of-us/:2:6","tags":["Functional","Programming","Lambda","History"],"title":"Programaci√≥n funcional para el resto de nosotros","uri":"/es/functional-programming-for-the-rest-of-us/"},{"categories":["Development","Parallel Series"],"content":"Ir al √≠ndice de la serie ","date":"2012-02-08","objectID":"/es/luces-camara-action/:0:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Luces, c√°mara... action!","uri":"/es/luces-camara-action/"},{"categories":["Development","Parallel Series"],"content":"Magia sin delegados Los delegados de tipo Action son una de las peque√±as maravillas tra√≠das a .NET desde la programaci√≥n funcional. Pueden definirse como un m√©todo que tiene un s√≥lo par√°metro (en su sobrecarga m√°s simple) y que no devuelve ning√∫n valor. Habitualmente suelen usarse para almacenar referencias a m√©todos o para pasar un m√©todo como par√°metro sin tener que declarar expl√≠citamente un delegado. Basta definir el par√°metro con la misma firma que se espera recibir y la magia empieza a actuar. Un detalle importante que podemos ver al observar la firma de Action es que el tipo T es contravariante, de modo que podemos usar este tipo en cualquier otro tipo derivado. Si quieres saber m√°s sobre covarianza y contravarianza en Generics dale un buen vistazo a este post del blog del colega Eduard Tom√†s. Veamos un poco de esta magia. Suponiendo que tenemos un m√©todo que admite un par√°metro de tipo Action podemos llamar al m√©todo y pasarle (o m√°s bien inyectarle) el comportamiento deseado, es decir pasarle un m√©todo que cumpla con la firma por par√°metro: void test() { string msg = \"This is the value...\"; doSomethingWithStringValue(enqueueMessage, msg); doSomethingWithStringValue(saveToDatabase, msg); doSomethingWithStringValue(writeMessageToConsole, msg); } private void doSomethingWithStringValue(Action\u003cstring\u003e actionToDo, string value) { //do several things with this value validateMessage(value); compressMessage(value); //when finishing... actionToDo(value); } private void enqueueMessage(string value) { //do something \u0026 enqueue this value Queue\u003cstring\u003e messages = new Queue\u003cstring\u003e(); messages.Enqueue(value); } private void saveToDatabase(string value) { //do something \u0026 save to db this value addLineToUserLog(value); } private void writeMessageToConsole(string value) { //do something \u0026 output this value Console.WriteLine(value); } Por un lado tenemos tres m√©todos que hacen cosas distintas pero tienen la misma firma (todos esperan un par√°metro de tipo string). Y por el otro tenemos un m√©todo que tiene un par√°metro de tipo Action. Es decir, este par√°metro admite como valor cualquier m√©todo que tenga la misma firma que hemos declarado. De este modo, podemos invocarlo varias veces y en cada una de ellas de podemos decir que utilice un m√©todo distinto para hacer algo distinto. Muy similar a las funciones as√≠ncronas de Javascript o al patr√≥n Promise. Bonito, eh? Es lo mismo que utilizar delegados pero, uhm‚Ä¶ espera! Si, sin usarlos üòÑ ","date":"2012-02-08","objectID":"/es/luces-camara-action/:1:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Luces, c√°mara... action!","uri":"/es/luces-camara-action/"},{"categories":["Development","Parallel Series"],"content":"Actions por todos lados Pues cada vez son m√°s las clases del framework que hacen uso de este tipo de delegados y de su hermano Func, que viene a ser lo mismo pero retornando un valor. Sin ir m√°s lejos, los m√©todos extensores de LINQ (Select, Where, OrderBy) utilizan Func y casi toda la TPL se basa en el uso de Action, desde los bucles For y ForEach de la clase est√°tica Parallel, hasta la creaci√≥n expl√≠cita de tareas mediante la clase Task. Por ejemplo, cuando deseamos ejecutar una tarea de forma as√≠ncrona, podemos utilizar el m√©todo StartNew de la clase Task.Factory. Este m√©todo tiene una sobrecarga en el que acepta un par√°metro de tipo Action o Func, y lo mejor de todo es que puede crearse inline (en l√≠nea), es decir en el mismo momento en que se realiza la llamada. Veamos unos ejemplos: Partiendo de un m√©todo simple: private void doSomething() { //Pause for 0 to 10 seconds (random) Random r = new Random(Guid.NewGuid().GetHashCode()); Thread.Sleep(r.Next(10000)); } Puesto que es un m√©todo que ni recibe par√°metros ni devuelve nada podemos llegar a utilizar su sobrecarga m√°s sencilla: Task.Factory.StartNew(doSomething); Otra opci√≥n, si el m√©todo tuviese un par√°metro int para especificar el n√∫mero de segundos (en lugar de ser aleatorio) podr√≠a ser esta: private void doSomething(int seconds) { int mseconds = seconds * 1000 Thread.Sleep(mseconds); } Task.Factory.StartNew(() =\u003e doSomething(5)); Aqu√≠ ya vemos algo m√°s curioso. Algo que seguramente hemos observado muchas veces y utilizado antes: Una expresi√≥n lambda. Esta expresi√≥n es tambi√©n algo tomado de la programaci√≥n funcional, y puede leerse como: ‚Äúva hacia‚Äù. En la parte izquierda de la expresi√≥n se especifican los par√°metros de entrada o variables (si existen, en este caso no), y en la parte derecha la propia expresi√≥n. El caso anterior es tan simple que no tiene par√°metros y s√≥lo usamos la parte derecha de la expresi√≥n para enviar el valor 5 al m√©todo. Al usar una expresi√≥n lambda se permite que las instrucciones contenidas en dicha expresi√≥n puedan varias l√≠neas, de modo que tambi√©n podemos llegar a hacer algo como esto: Task.Factory.StartNew(() =\u003e { int x = 5; doSomething(x); Console.WriteLine(\"finished!\"); }); O directamente esto: Task.Factory.StartNew(() =\u003e { int x = 5; int mseconds = seconds * 1000 Thread.Sleep(mseconds); Console.WriteLine(\"finished!\"); }); En este caso, podemos incluso omitir el m√©todo doSomething y usar el c√≥digo inline directamente en la llamada a StartNew. No obstante, un consejo: No es conveniente abusar de las expresiones inline, de modo que si tenemos m√°s de 5 √≥ 6 l√≠neas tal vez ser√° m√°s conveniente refactorizar este c√≥digo para no hacerlo demasiado complejo y respetar los buenos principios de dise√±o. ","date":"2012-02-08","objectID":"/es/luces-camara-action/:2:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Luces, c√°mara... action!","uri":"/es/luces-camara-action/"},{"categories":["Development","Parallel Series"],"content":"Ahora con par√°metros Hasta ahora al realizar la llamada siempre hemos usado un delegado de tipo Action sin par√°metros, de ah√≠ los par√©ntesis vac√≠os en la parte izquierda de la expresi√≥n lambda. Sin embargo encontraremos multitud de casos en los que debemos pasar par√°metros. Sin ir m√°s lejos el m√©todo Parallel.For tiene un par√°metro de tipo Action al que hay que pasarle un valor de tipo int, l√≥gico por otra parte ya que dentro de un bucle es muy necesario conocer en todo momento el valor de la iteraci√≥n: Parallel.For(1, 40, (i) =\u003e { serie.Add(i.Fibonacci()); }); Observar que no es necesario definir el tipo de datos de la variable i porque el propio compilador es capaz de inferirlo, pero evidentemente tambi√©n podemos declarar el tipo previo al nombre de la variable, como siempre (int i). Podemos pasar tantos par√°metros como necesite la Action, el mismo m√©todo tiene otra sobrecarga que admite un objeto ParallelLoopState para poder cancelar el bucle: Parallel.For(1, 40, (i, loopState) =\u003e { serie.Add(i.Fibonacci()); if (i \u003e 35) loopState.Break(); }); Y por supuesto podemos crearnos nuestras propias acciones con tantos par√°metros como sean necesarios. Aunque al igual que ante, si necesitamos pasar m√°s de 3 √≥ 4 par√°metros a un Action tal vez deber√≠amos plantearnos si estamos haciendo las cosas bien private void saveToDatabase(string value, bool useDetails) { addLineToUserLog(value); if (useDetails) addLineToUserLogDetails(); } void test() { //Define una acci√≥n que apunta al m√©todo saveToDatabase Action\u003cstring, bool\u003e myAction = (v, s) =\u003e { saveToDatabase(v, s); }; string value = \"This is the value...\"; bool usedetails = true; myAction(value, usedetails); //Aqu√≠ se llama a la acci√≥n y al m√©todo al que apunta } ","date":"2012-02-08","objectID":"/es/luces-camara-action/:3:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Luces, c√°mara... action!","uri":"/es/luces-camara-action/"},{"categories":["Development","Parallel Series"],"content":"Resumiendo Los delegados de tipo Action son muy √∫tiles para simplificar el trabajo con delegados (ahora que lo pienso hace bastante tiempo que no los uso, ni para declarar eventos). Nos permiten especificar las acciones a realizar pudiendo llegar a tener hasta 16 par√°metros -demasiados en mi opini√≥n- y al igual que los m√©todo void no devuelven ning√∫n valor. Si queremos lo mismo pero pudiendo retornar un resultado debemos utilizar su hermano Func\u003cT, TResult\u003e que es exactamente igual, pero en todas sus sobrecargas (y tiene tantas como Action) el √∫ltimo argumento representa el valor de retorno. Ir al √≠ndice de la serie ","date":"2012-02-08","objectID":"/es/luces-camara-action/:4:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Luces, c√°mara... action!","uri":"/es/luces-camara-action/"},{"categories":["Development","Parallel Series"],"content":"Ir al √≠ndice de la serie ","date":"2011-06-26","objectID":"/es/parallelseries05-parallel-static-class/:0:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 05 - Parallel Static Class","uri":"/es/parallelseries05-parallel-static-class/"},{"categories":["Development","Parallel Series"],"content":"Parallel Static Class Hoy quiero hablaros de la clase est√°tica Parallel. Esta clase provee soporte para paralelizar bucles y regiones, y al igual que PLINQ su uso es muy sencillo. Cabe destacar que est√° especialmente optimizada para iteraciones, y que en este contexto se desenvuelve un poco mejor que PLINQ. No hay una diferencia significativa en tiempos absolutos, pero puede verse perfectamente si utilizamos el magn√≠fico profiler de Visual Studio 2010. No obstante, pueden existir situaciones en las que si se necesita afinar mucho el rendimiento en iteraciones, y aqu√≠ es d√≥nde tiene m√°s sentido utilizar dos de los tres m√©todos de esta clase: For y ForEach. Al tercero lo llamaremos Cirdan y apenas aparecer√° en esta historia (en realidad me refiero a Invoke pero tampoco aparecer√° por aqu√≠). ","date":"2011-06-26","objectID":"/es/parallelseries05-parallel-static-class/:1:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 05 - Parallel Static Class","uri":"/es/parallelseries05-parallel-static-class/"},{"categories":["Development","Parallel Series"],"content":"Comprendiendo las acciones Los dos m√©todos tienen una firma muy similar en su forma m√°s sencilla. Ambos iteran sobre una serie de instrucciones realizando n veces cada una de ellas. Y aqu√≠ es d√≥nde vemos aparecer los par√°metros de tipo Action: public static ParallelLoopResult For (int fromInclusive, int toExclusive, Action\u003cint\u003e body) public static ParallelLoopResult ForEach\u003cTSource\u003e (IEnumerable\u003cTSource\u003e source, Action\u003cTSource\u003e body) Un Action, al igual que su hermano Func es uno de los elementos de C# importados de la programaci√≥n funcional, y desde el momento en que uno se acostumbra a usarlo, cuesta pensar c√≥mo ha podido desarrollar toda su vida anterior. Si no, los que est√©is acostumbrados a usar expresiones lambda en LINQ, imagin√°os que desaparecen de un d√≠a para otro. No quiero empezar a divagar ahora sobre programaci√≥n funcional, aunque si que quiero hacer incapi√© en el uso de Actions y lo importantes que se han vuelto en los √∫ltimos a√±os. De hecho, recientemente he dedicado un post a c√≥mo Action y Func han simplificado mucho el trabajo con delegados a los desarrolladores. ","date":"2011-06-26","objectID":"/es/parallelseries05-parallel-static-class/:1:1","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 05 - Parallel Static Class","uri":"/es/parallelseries05-parallel-static-class/"},{"categories":["Development","Parallel Series"],"content":"El m√©todo Parallel.For Pero volviendo al tema que nos ocupa, si observamos la firma del m√©todo Parallel.For podremos ver que en lo importante no difiere demasiado de su hom√≥logo for de toda la vida: Ambos tienen un inicio, un final y unas acciones a realizar un n√∫mero determinado de veces. As√≠ que partiendo del m√©todo IsPrime que ya utilizamos en el anterior post sobre PLINQ, vamos a ver una comparativa entre las sintaxis de √©stos dos m√©todos: for (int i = 0; i \u003c 100; i++) { if(i.IsPrime()) Console.WriteLine(string.Format(\"{0} es primo\", i)); else Console.WriteLine(string.Format(\"{0} no es primo\", i)); } Parallel.For(0, 100, (i) =\u003e { if (i.IsPrime()) Console.WriteLine(string.Format(\"{0} es primo\", i)); else Console.WriteLine(string.Format(\"{0} no es primo\", i)); }); En ambos casos tenemos una serie de l√≠neas que deben ejecutarse 100 veces. Concretamente desde 0 hasta 99, ya que el elemento superior no se incluye en ninguno de los dos casos. S√≥lo se ve un poco extra√±o el uso del Action, pero pod√©is pensar en que la variable int i del primer bucle for, aqu√≠ se transforma en la parte (i) a la izquierda de la expresi√≥n lambda (=\u003e). Y las acciones a ejecutar del primer for son exactamente iguales y van a la derecha de la expresi√≥n lambda. ","date":"2011-06-26","objectID":"/es/parallelseries05-parallel-static-class/:1:2","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 05 - Parallel Static Class","uri":"/es/parallelseries05-parallel-static-class/"},{"categories":["Development","Parallel Series"],"content":"So, let‚Äôs parallelize! Vi√©ndolo de este modo debe resultar extremadamente sencillo transformar todos nuestros bucles de este modo, as√≠ que ¬ødebemos hacerlo? La respuesta es NO. En algunas ocasiones no vamos a obtener rendimiento por el hecho de paralelizar, ya que si el trabajo a realizar es m√≠nimo, tardaremos m√°s tiempo en dividir el trabajo en distintos threads, ejecutarlos y consolidar la informaci√≥n que en ejecutar la tarea sin paralelizar. Tambi√©n podr√≠a ser que nos encontr√°semos un cuello de botella externo en un dispositivo de I/O, como un puerto, un servidor remoto o un socket. Otro claro ejemplo de esto son los bucles anidados. Es com√∫n anidar varias estructuras for o foreach para realizar ciertos algoritmos. En este caso el candidato a ser paralelizado siempre es el bucle exterior y no es necesario (de hecho ser√≠a contraproducente) paralelizar los bucles internos: Parallel.For(0, 100, (z) =\u003e { for (int i = 0; i \u003c 100; i++) { if (i.IsPrime()) Console.WriteLine(string.Format(\"{0} es primo\", i)); else Console.WriteLine(string.Format(\"{0} no es primo\", i)); } }); Por lo pronto resulta bastante evidente, ya que si paralelizamos en bucle exterior necesitar√≠amos un ordenador con 100 cores y evidentementemente todav√≠a no existen, as√≠ que la TPL tiene que agrupar estas tareas para adaptarlas a los cores disponibles, tardando cierto tiempo en hacer la sincronizaci√≥n (parecido a los primeros ejemplos con monos de la serie). Imagin√°os entonces si paralelizamos ambos bucles: 100 x 100 = 10.000 cores? Simplemente no tiene sentido. Mi consejo es que en todos los casos en los que se decida paralelizar un bucle (y esto tambi√©n vale para las consultas PLINQ) se realice primero una comparativa de rendimiento. Tu amigo el profiler no enga√±a ;) ","date":"2011-06-26","objectID":"/es/parallelseries05-parallel-static-class/:1:3","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 05 - Parallel Static Class","uri":"/es/parallelseries05-parallel-static-class/"},{"categories":["Development","Parallel Series"],"content":"El m√©todo Parallel.ForEach En cuanto al m√©todo ForEach es pr√°cticamente igual al anterior con la salvedad que no tenemos un inicio y un final, sino una secuencia de entrada de datos (basada en IEnumerable, como PLINQ) y una variable que usamos para iterar por cada uno de los elementos de la secuencia y realizar una serie de acciones. Consideremos el siguiente c√≥digo: List\u003cFeedDefinition\u003e feeds = new List\u003cFeedDefinition\u003e(); clock.Restart(); var blogs = FeedsEngine.GetBlogsUrls(); foreach (var blog in blogs) { feeds.AddRange(FeedsEngine.GetBlogFeeds(blog)); } clock.Stop(); this.Text = clock.ElapsedMilliseconds.ToString(\"n2\"); feeds.ForEach(p =\u003e Console.WriteLine(p.Name)); Suponiendo que tenemos un m√©todo FeedsEngine.GetBlogsUrls que devuelve una lista de urls de proporcionan contenido RSS, el c√≥digo anterior se conecta a cada una de las urls e intenta descargar toda la informaci√≥n de los posts mediante un m√©todo FeedsEngine.GetBlogFeeds(blog). Nota: El c√≥digo completo lo podr√©is encontrar en el post (todav√≠a no publicado) ‚ÄòC√≥digo de ejemplo de las Parallel Series‚Äô, que contiene todos los ejemplos de todos los posts de la serie. Como pod√©is imaginar este proceso totalmente secuencial es un serio candidato a ser paralelizado, ya que la mayor√≠a del tiempo de este proceso es tiempo desperdiciado intentando a conectar con un servidor externo y que √©ste responda a las peticiones. En este caso paralelizar va a ser de gran ayuda aunque es importante comprender que en este caso la ganancia de rendimiento no va a ser por usar m√°s potencia local, sino por lanzar las peticiones a los distintos servidores de forma as√≠ncrona. As√≠ pues, basta cambiar la parte del bucle foreach por su versi√≥n paralelizada: Parallel.ForEach(blogs, (blog) =\u003e { feeds.AddRange(FeedsEngine.GetBlogFeeds(blog)); }); En la que definimos la secuencia de datos a utilizar y declaramos la variable blog al vuelo (el compilador infiere el tipo autom√°ticamente) a la izquierda de la expresi√≥n lambda, y a la derecha las acciones que deseamos realizar, que son exactamente iguales a la anterior versi√≥n foreach. Y comprobaremos como se ejecuta mucho m√°s r√°pido. En mi estaci√≥n de trabajo pasamos de 6,7 segundos a 1,4 lo que no est√° nada mal. ","date":"2011-06-26","objectID":"/es/parallelseries05-parallel-static-class/:1:4","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 05 - Parallel Static Class","uri":"/es/parallelseries05-parallel-static-class/"},{"categories":["Development","Parallel Series"],"content":"Explorando m√°s opciones En la clase Parallel al igual que en las consultas PLINQ, existe la posibilidad de especificar el grado de paralelismo as√≠ como de cancelar la ejecuci√≥n de un bucle. S√≥lo debemos usar una de las sobrecargas que utiliza un objeto de tipo ParallelOptions. private void button11_Click(object sender, EventArgs e) { CancellationTokenSource cs = new CancellationTokenSource(); var cores = Environment.ProcessorCount; clock.Restart(); var options = new ParallelOptions() { MaxDegreeOfParallelism = cores / 2, CancellationToken= cs.Token }; try { Parallel.For(1, 10, options, (i) =\u003e { dowork_cancel(i, cs); }); } catch (Exception ex) { MessageBox.Show(ex.Message); } clock.Stop(); this.Text = clock.ElapsedMilliseconds.ToString(\"n2\"); } void dowork_cancel(int i, CancellationTokenSource cs) { Thread.Sleep(1000); if (i == 5) cs.Cancel(); } En el caso anterior especificamos un grado de paralelizaci√≥n de la mitad del n√∫mero de cores y preparemos la consulta para su posible cancelaci√≥n (algo que simulamos en el interior del m√©todo dowork_cancel al llegar el contador a 5). A continuci√≥n‚Ä¶ En el pr√≥ximo post veremos c√≥mo utilizar la clase est√°tica Parallel, optimizada para trabajar con procesos iterativos, esos t√≠picos bucles que todas las aplicaciones tienen. Ir al √≠ndice de la serie ","date":"2011-06-26","objectID":"/es/parallelseries05-parallel-static-class/:1:5","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 05 - Parallel Static Class","uri":"/es/parallelseries05-parallel-static-class/"},{"categories":["Development","Parallel Series"],"content":"Ir al √≠ndice de la serie ","date":"2011-05-31","objectID":"/es/parallelseries04-plinq/:0:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 04 - PLINQ","uri":"/es/parallelseries04-plinq/"},{"categories":["Development","Parallel Series"],"content":"LINQ power! Creo que estaremos todos de acuerdo en que LINQ ha supuesto una revoluci√≥n en la forma de desarrollar, y ha hecho que muchos desarrolladores de otros lenguajes nos miren con cierto tono de envidia‚Ä¶ E incluso que otras plataformas est√©n haciendo serios esfuerzos para incorporarlo en sus Frameworks :-) Ahora, con la llegada de la Task Parallel Library, se abre un mundo de posibilidades gracias a PLINQ, que permite -de forma extremadamente sencilla- convertir cualquier consulta LINQ secuencial en una consulta paralelizable, permitiendo su segmentaci√≥n y ejecuci√≥n en los distintos cores en paralelo. Es decir cualquier consulta LINQ, c√≥mo la siguiente, en la que tenemos un array llamado numbers y un m√©todo IsPrime que devuelve un valor boolean en funci√≥n de si un n√∫mero es primo. Suponiendo esta funci√≥n que devuelve si un n√∫mero es primo: public static bool IsPrime(this int n) //1 = false, 2 = true, 3 = true... { if (n \u003c= 1) return false; if ((n \u0026 1) == 0) { if (n == 2) return true; else return false; } for (int i = 3; (i * i) \u003c= n; i += 2) { if ((n % i) == 0) return false; } return n != 1; } Puede ser ejecutada con LINQ de este modo para que retorne s√≥lo aquellos n√∫meros que son primos: var query = from n in numbers where n.IsPrime() select n; Y √©sta ser paralelizada simplemente agregando AsParallel de este modo: var query = from n in numbers.AsParallel() where n.IsPrime() select n; Partiendo de que el array de n√∫meros contiene los primeros 10 millones de n√∫meros enteros, y de que mi estaci√≥n de trabajo actual tiene un procesador i7 con 8 cores, el resultado es abrumador: La consulta LINQ tarda 5,2 segundos frente a los 1,3 segundos de la segunda. Es decir, casi 4 segundos menos o un 400% m√°s r√°pido. Nada mal, eh? ","date":"2011-05-31","objectID":"/es/parallelseries04-plinq/:1:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 04 - PLINQ","uri":"/es/parallelseries04-plinq/"},{"categories":["Development","Parallel Series"],"content":"¬øD√≥nde est√° la magia? La magia verdadera es que PLINQ nos abstrae de todo el proceso de paralelizaci√≥n, creaci√≥n de tareas, threads, sincronizaci√≥n y consolidaci√≥n de los datos. Y adem√°s creo que lo hace de forma muy elegante :-) Como ya sabemos, las consultas LINQ se basan en IEnumerable (gracias Generics!) que expone un enumerador para recorrer los elementos de una secuencia de elementos de tipo T. Esto hace que todas las colecciones que puedan devolverse en este tipo de consultas (IOrderedEnumerable, IQueryable, etc.) implementen esta interfaz. Hasta aqu√≠ nada nuevo bajo el sol. Sin embargo, en la consulta PLINQ al utilizar el m√©todo extensor AsParallel() estamos transformando la secuencia de entrada de IEnumerable a ParallelQuery permitiendo la segmentaci√≥n de los elementos de la secuencia y ejecutando cada uno de los segmentos en un thread distinto. Y por supuesto, repartiendo el trabajo en los diversos cores (si los hay). Segmentaci√≥n en paralelo de la secuencia La secuencia de entrada se particiona y se manda por fragmentos a distintos threads que invocan al m√©todo IsPrime devolviendo true (T) o false (F), y posteriormente los consolida en una secuencia de salida que puede ser consumida. No obstante, el hecho de paralelizar el trabajo no garantiza que el resultado sea devuelto en el mismo orden, ya que es posible que un thread termine antes que otro y devuelva su resultado parcial antes de lo esperado. As√≠ que, si la ordenaci√≥n de los datos de salida es importante tenemos que ir un paso m√°s all√°. Los primeros elementos deber√≠an ser 2, 3, 5, 7‚Ä¶ no 59 y 71 ¬ø? ","date":"2011-05-31","objectID":"/es/parallelseries04-plinq/:1:1","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 04 - PLINQ","uri":"/es/parallelseries04-plinq/"},{"categories":["Development","Parallel Series"],"content":"PLINQ y la ordenaci√≥n Para asegurar la ordenaci√≥n del conjunto de resultados, basta agregar el m√©todo AsOrdered() a la consulta. Este m√©todo asegura la correcta ordenaci√≥n, a costa de implementar una serie de mecanismos de sincronizaci√≥n. Estos mecanismos, l√≥gicamente retardan un poco el tiempo de entrega de los resultados, pero es despreciable. En mi estaci√≥n de trabajo se arrojan unos valores de 1,311 segundos sin ordenar frente a 1,344 segundos ordenados (apenas 30 mil√©simas). Estos resultados son la media de una serie de 50 mediciones, con lo que son bastante fiables. Una vez modificada la consulta: var query = from n in numbers.AsParallel().AsOrdered() where n.IsPrime() select n; Ahora si est√°n ordenados :) ","date":"2011-05-31","objectID":"/es/parallelseries04-plinq/:1:2","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 04 - PLINQ","uri":"/es/parallelseries04-plinq/"},{"categories":["Development","Parallel Series"],"content":"Especificar el grado de paralelizaci√≥n En la mayor√≠a de las charlas que he dado sobre la TPL se acostumbra a preguntar respecto a funciones que acceden a recursos externos (servicios, sockets, etc.). En estos casos aparece claramente un cuello de botella, y no porque una funci√≥n necesite hacer uso intensivo de la CPU, sino porque debe esperar un resultado externo. Aqu√≠ suele ser interesante especificar el grado de paralelizaci√≥n de deseamos. Otro caso interesante para especificar el grado de paralelizaci√≥n puede ser el t√≠pico escenario de productor/consumidor. Es interesante notar que al especificar el grado de paralelizaci√≥n no estamos forzando a que se usen n particiones, sino que simplemente estamos especificando el valor m√°ximo: var cores = Environment.ProcessorCount; var query = from n in numbers.AsParallel().AsOrdered(). WithDegreeOfParallelism(cores / 2) where n.IsPrime() select n; De este modo, al definir el grado de paralelizaci√≥n en la mitad del n√∫mero de cores del procesador nos aseguramos que (por ejemplo) podremos tener un hilo que vaya creando elementos (productor) y otro hilo que vaya consumiendo dichos elementos (consumidor). ","date":"2011-05-31","objectID":"/es/parallelseries04-plinq/:1:3","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 04 - PLINQ","uri":"/es/parallelseries04-plinq/"},{"categories":["Development","Parallel Series"],"content":"Cancelaci√≥n de una consulta PLINQ En ocasiones, una consulta PLINQ puede ser cancelada. Bien porque durante el proceso se ha encontrado un error y ya no es necesario terminar de calcular el resto de resultados, o simplemente porque ha sido cancelada por el usuario. Es estos casos, es necesario utilizar un token de cancelaci√≥n. Este token tiene su origen en la estructura CancellationTokenSource, que representa ‚Äòuna potencial cancelaci√≥n‚Äô y proporciona los mecanismos para cancelar y comprobar el estado de una tarea as√≠ncrona, de modo que puede utilizarse con todos los elementos de la Task Parallel Library, no s√≥lo con PLINQ. A continuaci√≥n, vamos a modificar el c√≥digo del ejemplo que hemos usado hasta ahora para simular un error y comprobar el funcionamiento de la cancelaci√≥n de tareas en PLINQ. Para ello lo primero que vamos a hacer es crear una sobrecarga del m√©todo IsPrime, que reciba un par√°metro de tipo CancellationTokenSource, para poder cancelar la tarea: public static bool IsPrime(this int n, CancellationTokenSource cs) { if (n == 1000) cs.Cancel(); return IsPrime(n); } A modo de ejemplo, cuando el n√∫mero a calcular sea 1.000 cancelaremos la tarea, de modo que no sea necesario llegar a los 10 millones. De este modo, por un lado se lanzar√° una excepci√≥n y por otro el tiempo en ejecutar la consulta PLINQ ser√° mucho menor. private void plinq_cancellable() { var numbers = Enumerable.Range(1, 10000000); using (var cs = new CancellationTokenSource()) { var clock = Stopwatch.StartNew(); var query = numbers.AsParallel().AsOrdered(). WithCancellation(cs.Token). Where(p =\u003e p.IsPrime(cs)); try { var result = query.ToArray(); } catch (OperationCanceledException ex) { Console.WriteLine(ex.Message); } clock.Stop(); this.Text = clock.ElapsedMilliseconds.ToString(\"n2\"); } } Por un lado tenemos que tener la precauci√≥n de envolver la consulta dentro de un bloque try-catch (en este caso s√≥lo la llamada a ToArray() que es realmente cuando se ejecuta la consulta), y por el otro especificamos que la consulta puede ser cancelada mediante WithCancellation. A continuaci√≥n creamos un objeto de tipo CancellationTokenSource para administrar la cancelaci√≥n de esta consulta. Este objeto ser√° el que finalmente pasemos al m√©todo IsPrime() y en caso que se cancele provocar√° que su propiedad IsCancellationRequested devuelva true y que se produzca una bonita excepci√≥n de tipo OperationCanceledException. Al llegar a 1000... boom! ","date":"2011-05-31","objectID":"/es/parallelseries04-plinq/:1:4","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 04 - PLINQ","uri":"/es/parallelseries04-plinq/"},{"categories":["Development","Parallel Series"],"content":"Limitaciones de PLINQ No quiero extenderme mucho m√°s porque creo que hay material suficiente para hacer un post m√°s adelante sobre temas avanzados. Sin embargo quiero dejar claro que existen algunas limitaciones en PLINQ, como el uso de algunos operadores (Take, SkipWhile) y de las versiones indexadas de Select o ElementAt. Adem√°s existen otros casos en los que por cuestiones de rendimiento no es recomendable usar PLINQ en todos los casos, debido al sobrecoste que puede llegar a ocasionar, como el uso de Join, Union o GroupBy. Sin embargo, trataremos √©stas cuestiones m√°s adelante. Pr√≥ximamente veremos c√≥mo utilizar la clase est√°tica Parallel, optimizada para trabajar con procesos iterativos, esos t√≠picos bucles que todas las aplicaciones tienen. ","date":"2011-05-31","objectID":"/es/parallelseries04-plinq/:1:5","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 04 - PLINQ","uri":"/es/parallelseries04-plinq/"},{"categories":["Development","Parallel Series"],"content":"Video Aqu√≠ tienes un v√≠deo corto (15 minutos) sobre lo que acabamos de contar ;) A continuci√≥n‚Ä¶ En el pr√≥ximo post veremos c√≥mo utilizar la clase est√°tica Parallel, optimizada para trabajar con procesos iterativos, esos t√≠picos bucles que todas las aplicaciones tienen. Ir al √≠ndice de la serie ","date":"2011-05-31","objectID":"/es/parallelseries04-plinq/:2:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 04 - PLINQ","uri":"/es/parallelseries04-plinq/"},{"categories":["Development","Parallel Series"],"content":"Ir al √≠ndice de la serie ","date":"2011-03-03","objectID":"/es/parallelseries03-conceptos-base/:0:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 03 - Conceptos base","uri":"/es/parallelseries03-conceptos-base/"},{"categories":["Development","Parallel Series"],"content":"Elementos del sistema opertivo Cuando hablamos de programaci√≥n paralela conviene tener bastante claros algunos conceptos a nivel de sistema operativo. En este apartado trataremos de aclarar estos t√©rminos, ya que m√°s adelante los usaremos frecuentemente. ","date":"2011-03-03","objectID":"/es/parallelseries03-conceptos-base/:1:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 03 - Conceptos base","uri":"/es/parallelseries03-conceptos-base/"},{"categories":["Development","Parallel Series"],"content":"Procesos (Processes) Toda aplicaci√≥n ejecut√°ndose en el sistema operativo existe dentro del contexto de un proceso, aunque no todos los procesos se corresponden con aplicaciones visibles. Basta abrir el administrador de tareas para comprobar que la lista de procesos es bastante mayor a la de aplicaciones. Eso es as√≠ porque pueden corresponderse a servicios, aplicaciones no visibles o porque algunas aplicaciones est√°n dise√±adas para crear varios procesos (hola +ponga aqu√≠ el nombre de su explorador favorito+ üòÑ). Procesos de Windows en el Administrador de Tareas Un proceso proporciona los recursos necesarios para ejecutar un programa. Contiene un espacio de memoria virtual, c√≥digo ejecutable, un contexto de seguridad, un identificador de proceso √∫nico, variables de entorno, y al menos un thread de ejecuci√≥n. Un proceso de Windows Cada proceso se inicia con un √∫nico hilo (thread en adelante), a menudo llamado thread principal. Pero puede crear threads adicionales, que pueden ser utilizados para encargarse de diferentes tareas. Hacer llamadas entre procesos resulta complejo y muy costoso en t√©rminos de rendimiento debido a que deben usarse mecanismos especiales como pipes, sockets o llamadas RPC (Remote procedure call). ","date":"2011-03-03","objectID":"/es/parallelseries03-conceptos-base/:1:1","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 03 - Conceptos base","uri":"/es/parallelseries03-conceptos-base/"},{"categories":["Development","Parallel Series"],"content":"Dominios de aplicaci√≥n .NET (AppDomains) Al ser .NET una plataforma que ejecuta c√≥digo administrado, los procesos que se crean al ejecutar √©stas aplicaciones son un poco diferentes, ya que cuando se dise√±√≥ .NET una de las m√°ximas preocupaciones fue la de tratar de mejorar el manejo de los procesos cl√°sico o no administrados. Por ello se cre√≥ el concepto de dominio de aplicaci√≥n, que podr√≠a definirse como un proceso l√≥gico dentro del proceso del sistema operativo. Procesos en .NET Framework La gran diferencia es que dentro de un proceso podemos crear distintos dominios de aplicaci√≥n y cargar en cada uno de ellos varios ensamblados, y aprovechar que las llamadas entre distintos dominios de aplicaci√≥n y los ensamblados que contienen son mucho m√°s r√°pidas que entre procesos. Si uno de estos ensamblado debe ser compartido entre dos dominios de aplicaciones √©ste se copia en cada uno de los dominios. De este modo, al usar los dominios de aplicaci√≥n se obtiene la ventaja de aislar el c√≥digo de un proceso a otro, pero sin pagar el sobrecoste dedicado a realizar llamadas entre procesos. ","date":"2011-03-03","objectID":"/es/parallelseries03-conceptos-base/:1:2","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 03 - Conceptos base","uri":"/es/parallelseries03-conceptos-base/"},{"categories":["Development","Parallel Series"],"content":"Hilos (Threads) Un thread es la entidad dentro de un proceso encargada de ejecutar el c√≥digo. Todos los threads que contiene un proceso comparten los recursos y memoria virtual de √©ste, y mantienen controladores de excepciones, una prioridad de programaci√≥n, almacenamiento local, y un identificador de thread √∫nico. Los threads son independientes a los dominios de aplicaci√≥n, de forma que podemos pensar en ellos como elementos transversales que pueden saltar de un uno a otro a lo largo del tiempo. No existe ninguna correspondencia entre el n√∫mero de threads y de dominios de aplicaci√≥n. Por defecto, todos los procesos se crean con un thread por defecto llamado thread principal, aunque en las aplicaciones .NET se crean al menos dos, ya que es necesario un segundo thread para administrar el recolector de basura. No obstante cada proceso puede crear un n√∫mero casi ilimitado de ellos, aunque en √∫ltima instancia el sistema operativo siempre tiene la potestad de priorizar a la baja estos hilos o incluso congelarlos. Threads dentro de un proceso Realizar cambios de contexto entre threads es much√≠simo m√°s r√°pido que los cambios de contexto de proceso. De hecho en los sistemas operativos que utilizan multitarea preemptiva (la gran mayor√≠a hoy en d√≠a) el sistema operativo va cediendo una peque√±a fracci√≥n de tiempo a cada uno de los threads de cada uno de los procesos cargados para que ejecuten una porci√≥n de su c√≥digo ejecutable, dando la sensaci√≥n de que varias aplicaciones se ejecutan al mismo tiempo. Este tipo de multitarea tiene la ventaja frente a sus predecesores de que si un proceso deja de responder, el sistema no se colapsa y puede seguir respondiendo sin verse afectado por la ca√≠da del mismo. Esto en la pr√°ctica ha significado la casi desaparici√≥n de las llamadas BSOD (Blue Screen Of Death) causadas por este motivo. ","date":"2011-03-03","objectID":"/es/parallelseries03-conceptos-base/:1:3","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 03 - Conceptos base","uri":"/es/parallelseries03-conceptos-base/"},{"categories":["Development","Parallel Series"],"content":"Multihilo (Multithreading) A la capacidad que tienen los procesos de crear distintos threads ejecut√°ndose simult√°neamente es a lo que llamamos Multithreading. Y nos ha permitido simular la multitarea en los ordenadores personales de la √∫ltima d√©cada y media. Esto es as√≠ porque aunque f√≠sicamente s√≥lo haya un microprocesador, en t√©rminos del sistema operativo √©ste cede un periodo de tiempo a cada thread de cada uno de los procesos cargados en el sistema, y al repetirse una y otra muy r√°pidaamente vez produce la sensaci√≥n de que todas las aplicaciones se ejecutan al mismo tiempo, pero nada m√°s lejos de la realidad. Al menos hasta hace poco. Threads ejecut√°ndose en un core de procesdor ","date":"2011-03-03","objectID":"/es/parallelseries03-conceptos-base/:1:4","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 03 - Conceptos base","uri":"/es/parallelseries03-conceptos-base/"},{"categories":["Development","Parallel Series"],"content":"Paralelismo (Parallelism) Con la aparici√≥n de los primeros microprocesadores con varios n√∫cleos (cores), al fin se pudo ejecutar c√≥digo en paralelo y obtener la tan deseada multitarea real, ya que distintos threads pueden ejecutarse en distintos cores al mismo tiempo. De modo que a m√°s cores, m√°s threads pueden ejecutarse y por consiguiente m√°s c√≥digo al mismo tiempo. Threads ejecut√°ndose en varios cores a la vez Hace apenas cuatro o cinco a√±os de la aparici√≥n de los primeros dual core, s√≥lo un poco m√°s tarde aparecieron los quad core, y hoy en d√≠a es bastante habitual ver estaciones de trabajo con 8 y hasta 16 cores. En cuanto al futuro, nadie sabe al ritmo que evolucionar√° esta tecnolog√≠a, pero los chicos de Intel hace m√°s de dos a√±os ya filtraron im√°genes de un Windows Server con 256 cores. Incluso los s√∫per ligeros procesadores para tel√©fonos y tablets basados en arquitectura ARM est√°n empezando a lanzar modelos de dos y cuatro cores. Qui√©n quiere uno de estos? Volviendo al ejemplo de los monos, resulta muy tentador pensar que si aprovechamos toda la potencia de los nuevos n√∫cleos podemos obtener ganancias de rendimiento espectaculares y escribir los 200 tomos en el tiempo que escribimos uno de ellos. Evidentemente esta afirmaci√≥n es un poco exagerada, ya que siempre va a haber un arduo trabajo de sincronizaci√≥n entre los diferentes monos‚Ä¶ perd√≥n threads. Con todo, la ganancia es espectacular, llegando f√°cilmente a multiplicar x5 o x6 en un entorno con 8 cores. Algo nada despreciable en seg√∫n qu√© procesos. De modo que viendo el n√∫mero de cores hacia d√≥nde nos movemos, a mi juicio se hace imperativo conocer -si no dominar- la TPL. ","date":"2011-03-03","objectID":"/es/parallelseries03-conceptos-base/:1:5","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 03 - Conceptos base","uri":"/es/parallelseries03-conceptos-base/"},{"categories":["Development","Parallel Series"],"content":"Antes de terminar, un consejo Como hemos visto, por el momento s√≥lo puede existir paralelismo real en una estaci√≥n con varios cores. De otro modo el c√≥digo funcionar√° sin errores pero solo utilizando el √∫nico core de la m√°quina. As√≠ que un error bastante com√∫n entre los desarrolladores es utilizar m√°quinas virtuales para desarrollar, y olvidarnos que la mayor√≠a no permiten especificar varios cores. De modo que es bastante probable que alguna vez nos encontremos refunfu√±ando porque un c√≥digo bien escrito no obtiene ninguna ganancia cuando lo ejecutemos dentro de una maquina virtual üò† ","date":"2011-03-03","objectID":"/es/parallelseries03-conceptos-base/:2:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 03 - Conceptos base","uri":"/es/parallelseries03-conceptos-base/"},{"categories":["Development","Parallel Series"],"content":"Video Aqu√≠ tienes un v√≠deo corto (15 minutos) sobre lo que acabamos de contar ;) A continuci√≥n‚Ä¶ En el pr√≥ximo post veremos c√≥mo extender LINQ con Paralel LINQ, y de este modo dotar a nuestras consultas sobre listas enumerables de paralelismo, sin apenas impacto en el c√≥digo actual. Ir al √≠ndice de la serie ","date":"2011-03-03","objectID":"/es/parallelseries03-conceptos-base/:3:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 03 - Conceptos base","uri":"/es/parallelseries03-conceptos-base/"},{"categories":["Development","Parallel Series"],"content":"Ir al √≠ndice de la serie ","date":"2011-01-21","objectID":"/es/parallelseries02-un-poco-de-historia/:0:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 02 - Un poco de historia","uri":"/es/parallelseries02-un-poco-de-historia/"},{"categories":["Development","Parallel Series"],"content":"Un poco de historia La programaci√≥n paralela no es nada nuevo. Ya estaba presente all√° en mis tiempos de estudiante hace m√°s de 20 a√±os üò¢ y hoy en d√≠a, desde la aparici√≥n del .Net Framework 4.0 est√° m√°s viva que nunca gracias a la Task Parallel Library o TPL. No obstante, decir que la TPL s√≥lo sirve para realizar tareas as√≠ncronas es como decir que un smartphone s√≥lo sirve para llamar por tel√©fono. Es m√°s, much√≠simo m√°s. Y es precisamente, de la mano de √©sta librer√≠a que vamos a introducirnos en el apasionante mundo de la programaci√≥n paralela. Esta disciplina siempre ha estado tradicionalmente asociada a los perfiles t√©cnicos m√°s elevados y reservada para ocasiones especiales. Sin embargo a partir de ahora y gracias a la TPL va a ser accesible a todo tipo de desarrolladores, y se va a convertir en algo muy importante, algo que todo buen desarrollador deber√° a√±adir a su lista de activos. De hecho, va a ser una parte esencial en el futuro inmediato del desarrollo de aplicaciones a todos los niveles. Pero ¬øqu√© realmente es la programaci√≥n paralela? Podemos pensar en ella como en la posibilidad de dividir una tarea larga y pesada en varias tareas m√°s cortas, y ejecutar √©stas al mismo tiempo, de modo que tarde mucho menos que la tarea original. ","date":"2011-01-21","objectID":"/es/parallelseries02-un-poco-de-historia/:1:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 02 - Un poco de historia","uri":"/es/parallelseries02-un-poco-de-historia/"},{"categories":["Development","Parallel Series"],"content":"Enciclopedias y monos Supongamos que tenemos que copiar los 200 tomos de la gran enciclopedia gal√°ctica de T√©rminus. L√≥gicamente no es lo mismo copiarlos uno tras otro, que contratar a 200 monos mutantes entrenados para copiar, y sentarlos en 200 escritorios con sus 200 bol√≠grafos a copiar los 200 libros. Es evidente que -de ser posible- la segunda opci√≥n ser√≠a mucho m√°s r√°pida. A m√°s recursos (escritorios y bol√≠grafos) m√°s r√°pido terminaremos la tarea Pero ¬øqu√© sucede si s√≥lo tenemos 100 escritorios y bol√≠grafos? Pues que los monos van a tener que hacer cola y esperar su turno, de modo que cuando uno de los monos termine o se canse de escribir, deber√° ceder su turno al mono que espera, provocando por el camino algunas colas y enfados por parte de los monos, que son buenos trabajadores pero un poco particulares. Con todo, a menos que estalle una guerra siempre ser√° m√°s r√°pido que la primera opci√≥n, pero eso nos deja ya la primera conclusi√≥n: a m√°s recursos (escritorios y bol√≠grafos) m√°s r√°pido terminaremos la tarea. Y de paso vamos a tener que preocuparnos menos por gestionar los turnos y las esperas de los monos, con todo lo que conlleva. Porque como veremos m√°s adelante, en muchas ocasiones cuando trabajamos con monos o con threads el tiempo de sincronizaci√≥n es primordial, y puede marcar la diferencia entre el √©xito y el fracaso de nuestra aplicaci√≥n. Monos programando ","date":"2011-01-21","objectID":"/es/parallelseries02-un-poco-de-historia/:2:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 02 - Un poco de historia","uri":"/es/parallelseries02-un-poco-de-historia/"},{"categories":["Development","Parallel Series"],"content":"Leyes muertas y f√≠sica cu√°ntica Sin embargo, hasta ahora nos ha ido muy bien con la programaci√≥n tradicional as√≠ que ¬øporque parece ser que ahora es cuesti√≥n de vida o muerte aprender este nuevo paradigma? Es decir, habitualmente hasta ahora no hab√≠an demasiadas ocasiones en las que una aplicaci√≥n deb√≠a recurrir a la asincron√≠a o al paralelismo (que como veremos m√°s adelante no es exactamente lo mismo). Por qu√© ahora s√≠? La materia presenta efectos cu√°nticos que har√≠an necesaria una tecnolog√≠a diferente para seguir realizando c√°lculos a ese nivel La respuesta es sencilla, parece que la buena vida se termina. Si ha habido una constante en IT en los √∫ltimos 45 a√±os, esa es la que describe la ley de Moore: En 1965 Gordon Moore, uno de los fundadores de Intel predijo que cada 2 a√±os (18 meses al principio) se doblar√≠a el n√∫mero de componentes de un circuito integrado. Y se ha cumplido a rajatabla hasta hoy, aunque en los √∫ltimos a√±os se est√°n alcanzando ciertos l√≠mites que hacen que dicha ley no pueda seguir cumpli√©ndose. Ley de moore Simplificando un poco podr√≠amos decir que existen un par de problemas: El escalado de frecuencia de los microprocesadores y el calor generado por los mismos. El primero de ellos hace referencia a la dificultad de seguir incrementando la velocidad de los microprocesadores, debido principalmente a que la tecnolog√≠a utilizada para dise√±arlos est√° actualmente cerca de los 32 nan√≥metros y el l√≠mite f√≠sico antes de que la materia experimente cambios, se calcula que est√° entre los 22 y los 18 nan√≥metros. Esta previsto alcanzar este l√≠mite aproximadamente en s√≥lo dos o tres a√±os, hacia 2014. A la vuelta de la esquina. Una vez alcanzado ese nivel de miniaturizaci√≥n, en palabras del cient√≠fico Stephen Hawking: ‚ÄúLa materia presenta efectos cu√°nticos que har√≠an necesaria una tecnolog√≠a diferente para seguir realizando c√°lculos a ese nivel‚Äù. El segundo de los problemas va ligado al primero, y es que en los √∫ltimos a√±os el calor generado por los microprocesadores se ha ido incrementado exponencialmente, y en t√©rminos de densidad de potencia ya es igual al calor generado por la tobera de un cohete. Lo peor de todo ello es que incrementar la frecuencia s√≥lo entre un 5 y 10 por ciento cada a√±o, tiene un coste de casi doblar la temperatura. El futuro cercano Con esto no quiero decir que no puedan fabricarse ordenadores m√°s r√°pidos en un futuro. Quiero decir que si estas predicciones son acertadas, no podr√°n fabricarse microprocesadores m√°s r√°pidos con la tecnolog√≠a actual. Tal vez sea posible si se descubre c√≥mo construir ordenadores que utilicen tecnolog√≠a √≥ptica, nano-ingenier√≠a para crear transistores basados en nanotubos que aprovechen el llamado efecto t√∫nel, o cualquier otro concepto a√∫n por descubrir. Pero por el momento no podemos contar con ello. ","date":"2011-01-21","objectID":"/es/parallelseries02-un-poco-de-historia/:3:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 02 - Un poco de historia","uri":"/es/parallelseries02-un-poco-de-historia/"},{"categories":["Development","Parallel Series"],"content":"Deus ex machina Si por algo se ha caracterizado el ser humano es por su gran habilidad en resolver problemas (dejando aparte su nada desde√±able habilidad para provocarlos), de modo que ya hace unos a√±os que se ha empezado a desarrollar y fabricar una de las soluciones a este problema. De hecho hoy en d√≠a se ha convertido en algo casi cotidiano: Se trata de fabricar procesadores con varios n√∫cleos, que se repartan el trabajo -como los monos- consiguiendo as√≠ aumentar la velocidad. No por el hecho de ser cada vez m√°s r√°pidos, si no por existir cada vez m√°s recursos trabajando al mismo tiempo. Algo parecido -salvando las distancias- al cerebro humano, que en comparaci√≥n con un ordenador es bastante m√°s lento, pero su capacidad de procesamiento en paralelo gracias a sus millones de conexiones entre neuronas, no tiene rival con ning√∫n otro elemento conocido en la naturaleza ni creado por el hombre. Que nos depara el futuro? A continuci√≥n‚Ä¶ En el pr√≥ximo post aclararemos algunos conceptos b√°sicos aunque necesarios cuando desarrollamos aplicaciones que hagan uso de la programaci√≥n as√≠ncrona. Ir al √≠ndice de la serie ","date":"2011-01-21","objectID":"/es/parallelseries02-un-poco-de-historia/:4:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 02 - Un poco de historia","uri":"/es/parallelseries02-un-poco-de-historia/"},{"categories":["Development","Parallel Series"],"content":"Ir al √≠ndice de la serie ","date":"2011-01-11","objectID":"/es/parallelseries01-el-alfa/:0:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 01 - El Alfa","uri":"/es/parallelseries01-el-alfa/"},{"categories":["Development","Parallel Series"],"content":"Prologo Cada versi√≥n del .NET framework nos sorprende con una serie de novedades, y para cada uno de nosotros hay -al menos- una que nos roba el coraz√≥n. A mi me sucedi√≥ con la aparici√≥n de Generics con el framework 2.0, los m√©todos extensores y LINQ en las versiones 3.0 y 3.5 y me ha pasado de nuevo con la Task Parallel Library en la versi√≥n 4.0. Pens√°ndolo detenidamente tampoco no es tan extra√±o, al fin y al cabo siempre me ha gustado la programaci√≥n as√≠ncrona (algo que si alguien le llega a contar a alguno de mis primeros maestros de tecnolog√≠a digital, se habr√≠a muerto de la risa). Sin embargo, con los a√±os √©ste que escribe ha llegado -m√°s por tozudez que por talento natural- a conocer un poco los entresijos de la programaci√≥n as√≠ncrona. Una disciplina en la que tan importante es saber lo que hay que hacer, como lo que no hay que hacer. As√≠ pues, cuando lleg√≥ a mis manos la primera preview de Visual Studio 2010, una de las primeras cosas que hice fue mirar que demonios era eso de la Task Parallel Library. Primero porque ya hac√≠a un tiempo que hab√≠a escuchado acerca de la muerte anunciada de la ley de Moore. Y segundo porque cualquier cosa que hiciese m√°s llevadero el trabajo de realizar y depurar aplicaciones multihilo, bienvenido iba a ser. Task Parallel Library Desde entonces hasta ahora he tenido la suerte de poder dedicar un poco de tiempo a esta maravilla, de modo que me he propuesto crear una serie bastante larga de posts y v√≠deos sobre el tema. M√°s que nada porque a mi juicio hay poca documentaci√≥n (al menos en Espa√±ol) y algo as√≠ no puede quedar relegado al olvido. Y es que en multitud de ocasiones que cuando le explico a alguien el porqu√© es importante y en que consiste la TPL, acostumbra a decir: ‚ÄúQue guapo! Pues no ten√≠a ni idea‚Ä¶‚Äù. Y eso, me mata. ","date":"2011-01-11","objectID":"/es/parallelseries01-el-alfa/:1:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 01 - El Alfa","uri":"/es/parallelseries01-el-alfa/"},{"categories":["Development","Parallel Series"],"content":"Nacen las Parallel Series En los pr√≥ximos posts voy a ir definiendo el √≠ndice de contenidos de la serie, aunque a medida que crezca la serie es m√°s que probable que vaya siendo modificado y ampliado. Tambi√©n veremos algo de historia para ponernos en contexto, aclararemos conceptos base que van a ser necesarios m√°s adelante, e iremos desgranando los apartados principales de la Task Parallel Library. La idea es empezar desde abajo e ir subiendo de nivel, hasta llegar a los aspectos m√°s complejos, como los problemas de concurrencia o la depuraci√≥n de este tipo de aplicaciones. En cada apartado prometo poner al menos un ejemplo y si puedo m√°s, porque los humanos -y los developers heredamos de esta clase base- aprendemos mucho mejor los conceptos te√≥ricos si van acompa√±ados de la pr√°ctica. Nos vemos muy pronto ;-) A continuci√≥n‚Ä¶ En el pr√≥ximo post repasaremos la historia de la programaci√≥n paralela y veremos c√≥mo hemos llegado aqu√≠. Ir al √≠ndice de la serie ","date":"2011-01-11","objectID":"/es/parallelseries01-el-alfa/:2:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series 01 - El Alfa","uri":"/es/parallelseries01-el-alfa/"},{"categories":["Development","Parallel Series"],"content":"√çndice de contenidos 01 - El Alfa (Pr√≥logo) 02 - Un poco de historia 03 - Aclarando conceptos base 04 - PLINQ: Parallel LINQ 05 - Parallel static class 06 - Tasks, la 8¬™ maravilla 07 - Problemas de concurrencia 08 - Materiales y presentaciones de mis eventos ","date":"2011-01-10","objectID":"/es/parallelseries00-index/:1:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series - Indice","uri":"/es/parallelseries00-index/"},{"categories":["Development","Parallel Series"],"content":"Relacionados Programaci√≥n funcional para el resto de nosotros Luces, c√°mara‚Ä¶ Action! ","date":"2011-01-10","objectID":"/es/parallelseries00-index/:2:0","tags":["csharp","net framework","Task","Parallel","Async"],"title":"Parallel Series - Indice","uri":"/es/parallelseries00-index/"}]